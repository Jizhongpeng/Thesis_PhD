\chapter{Conclusions and Future work}
This work explored the characteristics of plenoptic imaging using a wave optics simulation toolbox to understand and evaluate its performance at the diffraction limit.
This research work can be divided in two parts. \\
The first part involved the design and the development of a wave optics simulation platform for light propagation in an optical system. The Fresnel simulation toolbox was developed using MATLAB and at the time this research started represented the first attempt to apply wave optics propagation to a plenoptic imaging system.\\ 
The second part described the simulations performed to understand and test this new class of imaging systems. The information collected during this
second section was useful to determine the potential as well as the drawback of
this technique and to design and develop a working prototype of plenoptic microscope. \\ 
Chapter one provides an overview of this technology describing the work done by other research groups. A detailed description of the geometric optics principles that describes the behaviour was given. The light collected by the optical system can be described using the concept of phase space which is a representation of the ray's distribution on the image plane. The phase space has the property that all the linear operations on its elements are invertible. Therefore it is possible to apply linear operators to the light distribution in the phase space so to enable several interesting post processing features.\\
The second chapter describes the simulation software designed and developed in MATLAB. This wave optics approach represents an important innovation for the field since it extends and improves on the ray tracing techniques that preceded it. An optical system is modelled as a combination of two basic operators: free space propagation and lens operator. The free space propagation operator was derived form the scalar theory of diffraction. A particular solution of the Helmholtz equation gives an expression to compute the optical field after a propagation of a distance z, the Fresnel approximation approach. Its drawback is that the output field has a different resolution than the input field. To overcome this fact a second method that keeps the resolution of the propagating field constant along the propagation path was described: this is the multi step Fresnel method. Its drawback is the long computational time due to the fact that for each step of the propagation the computation of a Fourier transform is required. In addition to that, noise keeps on adding at every step.\\
To address these issues the free space propagation operator was implemented using the Angular Spectrum of plane waves. Propagation is seen as a linear filter operating on the input field with a characteristic transfer function whose bandwidth depends on the propagation distance \textit{z}. This method keeps the same resolution in both the input and output field and requires only two Fourier transforms for any propagation distance \textit{z}. Its drawback is aliasing which arises in the propagation transfer function in the case of large propagation distances. To avoid aliasing the Band Limited Angular spectrum method and the Corrected Band Limited Angular Spectrum method were developed. These methods apply the Nyquist theorem to the transfer function so that the bandwidth of the propagation transfer function is truncated at the Nyquist frequency. The larger the propagation distance, the narrower the transfer function bandwidth will be and important information might be lost. The main novel contribution from this chapter is the Corrected Band Limited Angular Spectrum method. It extends the bandwidth of the truncated transfer function to a value determined by considering the aperture of the main lens and the propagation distance. This method provides a better signal to noise ratio since the noise due to the aliasing does not have such an adverse effect on the image as the loss of information due to the excessive limitation of the transfer function bandwidth.
\\ 
The third chapter focusses on simulating a plenoptic 1.0 system. After describing the simulation set up, a set of experiments to validate the results found in literature on the optical performances of plenoptic 1.0 were presented. A new contribution to light field imaging is the definition of a threshold on the micro array design in order to avoid cross talk between sub images due to diffraction. This result would have been impossible with a conventional ray tracing approach. An important result of this chapter is the verification that using wave optics of the post processing rendering algorithms described by Ng \cite{ng2006digital} and based on geometrical optics considerations work on generated data. Therefore a wave optics simulation toolbox can accurately simulate plenoptic images. Another achievement is the definition of the synthetic refocusing operator as a shearing operator acting on the four dimensional array describing the light field. This matrix-operator approach is not intuitive but it is very efficient from a computational point of view because of the matrix oriented nature of the MATLAB programming language. In fact operating a single shearing operation on a four dimensional array is computationally more efficient than obtaining the same results with nested for loops on the two dimensional raw data. This is only valid if using the MATLAB runtime engine.\\
The last important achievement presented in this section is the development of depth estimation method based on the creation of a focal planes stack and on the evaluation of the sharpness of each rendered image. Future work should focus on finding ways to optimise the accuracy of this method and to develop more efficient and automated algorithms.\\ 
The fourth chapter applies the simulation platform developed in chapter \ref{chap:fresnel} to a plenoptic 2.0 system. After validating the theory of Georgiev and Lumsdaine \cite{georgiev2010focused} a detailed study of the diffraction effects on plenoptic 2.0 imaging system was done. The most important result presented is the definition and the characterization of the effects of the micro lens array magnification on the optical resolution in the rendered image. This has been done using the simulation platform to analyse the impulse response of the system with different configurations of the micro lens array as well as evaluating the Rayleigh criterion of resolution. A more accurate frequency analysis was done by simulating a varying frequency sinusoidal pattern. The main result of this section is a quantification of the trade-off between directional and optical resolution in a plenoptic 2.0 imaging system. All these achievements have never been formalised in literature. \\
The fifth chapter describes a laboratory optical setup designed and realised using the experience and the understanding of plenoptic imaging achieved while working on the simulation platform. The result is a prototype of a plenoptic microscope whose optical and directional resolution can be changed by varying the position of the micro lens array. The experimental results matched the simulation results, providing a further proof of the robustness and reliability of the Fresnel propagation simulation toolbox.\\
This work represents an important milestone in the field of computational imaging since it provides a complete view of the behaviour of this class of instruments including at the diffraction limit. When wave optics is taken into account the trade off between spatial and angular resolution typical of a plenoptic imaging system must be expanded to include the optical resolution as well. The effects of diffraction in plenoptic 1.0 cameras are cancelled by the low resolution of the final rendered image. The only wave optics effect that comes into play is the cross talk between neighbouring lenslets, an effect that can be avoided using the design requirements explained in chapter \ref{chap:chapter4}. In plenoptic 2.0 diffraction effects have a bigger influence on the final rendered image. Since the angular resolution is linked to the directional resolution future research should be focused on finding ways to improve the optical resolution without limiting too much the set of directional coordinates sampled by the device. \\
This can be achieved either by improving the optics of the device or the computational rendering algorithms. Most of the literature to date describes methods to recover the full sensor resolution, even pushing to sub pixel resolution. But the problem of loss of information from adding a micro lens array between the main lens and the sensor plane remains. 
\\
This is an intrinsic characteristic of plenoptic imaging. The finite dimensions of the lenslets together with the wave nature of light produce a physical limit to the amount of information that can be achieved sampling the optical fields with those kind of devices. The set of directions of the rays of light collected by a plenoptic device describe all the possible features of the object imaged. Some of these directions are lost because of the finite aperture of the main lens, of the lenslets and because of diffraction. 
\\
In addition to that there is the trade off between spatial and directional resolution. In plenoptic 1.0 spatial resolution depends on the number of lenslets, and directional resolution on their size. Bigger lenslets give better directional resolution and poor spatial resolution. On the other hand small lenslets would give higher spatial resolution and a lower number of directional samples. Research presented in this thesis has enhanced this understanding by adding the effects of cross talk between lenslets; this is larger for small lenslets due to increased diffraction effects. In plenoptic 2.0 spatial resolution is not linked any more to the number of lenslets, and therefore high resolution rendered images are possible even with a small number of lenslet in the micro array. The presence of the micro lens array though, represents a limitation to the optical resolution. This results in a loss of information in the rendered image if compared with an image obtained from a conventional optical system. A way to overcome this intrinsic limitation is to remove the micro array stage for sampling the light field with other methods, such as compressive imaging.
To conclude this work a few words should be said on the future direction that research in plenoptic imaging should take. \\
Plenoptic imaging devices record the direction of the rays of light. Since a wave front is defined as the surface perpendicular to the direction of the rays, plenoptic imaging devices can be used to reconstruct the wave front of the propagating optical field along all the propagation path. This would enable applications in aberration evaluation and correction. Due to the non linearity of the effect of aberrations on images it is not possible to simply define an operator to recover the non-aberrated wave front from raw data of an aberrated image. A more complex analysis should be performed and further investigations on the mathematical instruments needed to perform such a transformation should be carried on. Methods from this thesis could be used to perform a digital adaptive optics loop, where the same instrument could measure the wave front and the image, estimates an appropriate transformation of the set of rays in the phase space and perform this transformation directly on the four dimensional array leading to an image in which the aberrations have been corrected. \\
In conclusion, plenoptic imaging is a very complex and mostly unexplored field. From creating the tools to do this investigation, the Matlab toolbox, some important results have been achieved on the effects of wave optics and especially in quantifying how diffraction represents a limitation in plenoptic imaging performance. This work still resides in the family of the preliminary studies and its purpose is to give a general view of the effects of diffraction on this class of instruments.\\ 

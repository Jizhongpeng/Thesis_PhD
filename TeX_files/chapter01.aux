\relax 
\citation{zhou2011computational}
\citation{nayar2006computational}
\citation{adelson1991plenoptic}
\citation{adelson1991plenoptic}
\citation{nayar2006computational}
\citation{nayar2006computational}
\citation{nayar2006computational}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Theory and Methods of Plenoptic Imaging}{41}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:chapter1}{{1}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{41}}
\newlabel{sec:intro1}{{1.1}{41}}
\citation{adelson1991plenoptic}
\citation{adelson1992single}
\citation{adelson1991plenoptic}
\citation{wetzstein2011computational}
\citation{adelson1991plenoptic}
\citation{levoy1996light}
\citation{georgiev2010focused}
\citation{levoy1996light}
\citation{levoy1996light}
\citation{levoy1996light}
\citation{georgiev2006light}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Differences between a traditional camera and a computational camera \cite  {nayar2006computational}.}}{43}}
\newlabel{fig:systems}{{1.1}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Plenoptic Function and the Light Field}{43}}
\newlabel{sec:lightfield}{{1.2}{43}}
\newlabel{eq:lightfield}{{1.1}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Two point representation of the light field. Each ray of light is uniquely defined by the coordinates of two points of interception.}}{45}}
\newlabel{fig:lightfield}{{1.2}{45}}
\citation{ng2006digital}
\citation{adelson1992single}
\citation{adelson1992single}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Point angle representation of the light field. A ray of light is uniquely defined by the coordinates of a point that belongs to a plane perpendicular at the optical axis z and by the angles $\theta _x$ and $\theta _y$ that it forms with the optical axis along the directions x and y.}}{46}}
\newlabel{fig:lightfield2}{{1.3}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Plenoptic Camera}{46}}
\newlabel{sec:plenoticcamera}{{1.3}{46}}
\citation{ng2005light}
\citation{georgiev2010focused}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces  Plenoptic camera and its fundamental components. The presence of the micro array allows to record the light field .}}{47}}
\newlabel{fig:plenoptic1}{{1.4}{47}}
\citation{adelson1992single}
\citation{ng2005light}
\citation{ng2006digital}
\citation{ng2005light}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Top: Plenoptic camera 1.0. The main lens is focused on the object and forms an image on the micro array. $f$ is the focal length of the main lens and $f_\mu $ the focal length of the micro lens array. Bottom: Plenoptic camera 2.0. The main lens is focused on an object and forms an image on the plane represented by the dashed line. The micro array acts as a relay between the main lens image and the sensor, satisfying the lens equation $1/a+1/b=1/f_\mu $.}}{48}}
\newlabel{fig:plenoptic2}{{1.5}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Plenoptic Camera 1.0}{49}}
\newlabel{sec:camera10}{{1.4}{49}}
\citation{levoy1996light}
\citation{levoy2006microscope}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Ray diagram of a plenoptic 1.0 system. The main lens is in a 2f configuration and the sensor plane is conjugated with the main lens plane. The micro lens position maps the position (x,y) of the point P, while the sub image maps the directions of the rays coming from that point. The ray with direction $\theta _1$ falls on the pixel 1 (blue), the ray with direction $\theta _2$ falls on the pixel 2 (green) and the ray with direction $\theta _3$ falls on the pixel 3 (red). The sub image $d$ maps the direction of the rays. }}{50}}
\newlabel{fig:plenoptic3}{{1.6}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces  Sampling of Light Field. Each ray is described by a set of four coordinates, two spatial (x,y) and two directional (u,v). The spatial coordinates are sampled by the position of the lenslet in the micro array, the directional coordinates are sampled by the pixel under the lenslet.}}{52}}
\newlabel{fig:plenoptic4}{{1.7}{52}}
\newlabel{eq:f_num}{{1.2}{52}}
\newlabel{eq:NA}{{1.3}{52}}
\citation{ng2005light}
\newlabel{eq:fnum1}{{1.4}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces F-number matching between the main lens and the micro lens in the array. }}{53}}
\newlabel{fig:plenoptic5}{{1.8}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces When the f-number is matched, all the rays captured by the main lens are mapped on the sub image (yellow). If the f-number of the lenslet is smaller (red), the sub image is smaller and there is an under sampling of the set of rays. If the f-number of the lenslet is bigger (green), the sub image is larger and cross talk happens between neighbouring sub images . }}{54}}
\newlabel{fig:plenoptic7}{{1.9}{54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Phase Space in Plenoptic 1.0}{55}}
\newlabel{sec:phase_space}{{1.4.1}{55}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Sampling of the light field and phase space representations of the rays. }}{56}}
\newlabel{fig:plenoptic6}{{1.10}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Light Field Parameterization}{57}}
\newlabel{sec:LFparam}{{1.4.2}{57}}
\citation{ng2006digital}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces  Image used as an object in the simulations.}}{58}}
\newlabel{fig:lenafull}{{1.11}{58}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Left: Example of a raw plenoptic 1.0 image. Right: Zoom on the raw image of the region indicated with the red square. Each lenslet is formed by 20 $\times $ 20 pixels. Each pixel represents a direction of the rays hitting the lenslet that produced the sub image. }}{58}}
\newlabel{fig:rawlena10}{{1.12}{58}}
\citation{levoy1996light}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces The array view is an array of the different point of view obtained rearranging the pixels according to the directional coordinates. }}{59}}
\newlabel{fig:arrayview}{{1.13}{59}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces Array view of the raw data shown in figure 1.12\hbox {}. }}{61}}
\newlabel{fig:arrayview1}{{1.14}{61}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces Zoom of the central part of the array view showing in detail the different points of views. }}{61}}
\newlabel{fig:arrayview1z}{{1.15}{61}}
\citation{georgiev2010focused}
\citation{ng2006digital}
\citation{ng2006digital}
\citation{ng2006digital}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Plenoptic 1.0 Rendering}{62}}
\newlabel{sec:rendering1}{{1.5}{62}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.16}{\ignorespaces  The intensity of a single pixel is obtained summing all the rays of light coming from all the possible directions.\cite  {ng2006digital} }}{62}}
\newlabel{fig:render1}{{1.16}{62}}
\citation{kerr2007derivation}
\citation{georgiev2010focused}
\citation{georgiev2010focused}
\citation{georgiev2010focused}
\newlabel{eq:rendering1}{{1.5}{63}}
\newlabel{eq:rendering2}{{1.6}{63}}
\newlabel{eq:rendering3}{{1.7}{63}}
\citation{georgiev2010focused}
\citation{ng2006digital}
\@writefile{lof}{\contentsline {figure}{\numberline {1.17}{\ignorespaces  Rendering an image from plenoptic 1.0 raw data is equal to summing all the directional samples for each position. This process is shown for the $(x,\theta _x)$ slice of the phase space. \cite  {georgiev2010focused} }}{64}}
\newlabel{fig:rendering2}{{1.17}{64}}
\citation{georgiev2010focused}
\citation{lumsdaine2008full}
\citation{lumsdaine2009focused}
\citation{georgiev2010focused}
\citation{bishop2011full}
\citation{georgiev2009resolution}
\citation{georgiev2010focused}
\@writefile{lof}{\contentsline {figure}{\numberline {1.18}{\ignorespaces  rendered image from the raw data in figure 1.12\hbox {}. Resolution is only 75 $\times $ 75 pixels. }}{65}}
\newlabel{fig:renderlena}{{1.18}{65}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Plenoptic Camera 2.0}{65}}
\newlabel{sec:pleno20}{{1.6}{65}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.19}{\ignorespaces  If the main lens image is formed in front of the micro array the configuration is called \textit  {Copernican}, top, and the focal length of the micro array is smaller then the distance b. If the main lens image is formed behind the micro array the configuration is \textit  {Galilean}, on the bottom, and the focal length of the micro array is bigger then the distance b. }}{67}}
\newlabel{fig:pleno201}{{1.19}{67}}
\newlabel{eq:pleno20}{{1.8}{67}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.20}{\ignorespaces  Raw data of a point source sampled by a plenoptic 2.0 system with a magnification of the micro array stage equal to 0.3. Data acquired with numerical simulations. }}{69}}
\newlabel{fig:rawpleno20}{{1.20}{69}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.21}{\ignorespaces  Zoomed raw data of a point source sampled by a plenoptic 2.0 system with a magnification of the micro array stage equal to 0.3. Data acquired with numerical simulations. The grid represent the boundaries of each sub image to show how the point of view of the point source changes across the lenslets. The sub images are shifted by a quantity proportional to the position of the lenslet in the array. }}{69}}
\newlabel{fig:rawpleno203}{{1.21}{69}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.22}{\ignorespaces Sampling of the light field by a plenoptic 2.0 system with a magnification of \textit  {m=0.3}. For simplicity the one dimensional case is shown. Each micro lens has a diameter equal to d, a focal length $f_{\mu }$, and images the main lens image on the sensor according to the lens law $1/a+1/b=1/f_{\mu }$ The total range of directions that can be sampled is given by $d/b$. Each lenslet samples a sub set of directions equal to $d/a$ as a single direction. The range of directions shown in red are sampled by the central micro lens as a single point of view. The angular resolution is therefore \textit  {d/a} and the total number of directional samples is \textit  {a/b = 1/m}. In the specific case shown is 3. }}{70}}
\newlabel{fig:rawpleno202}{{1.22}{70}}
\newlabel{eq:magnification}{{1.9}{70}}
\citation{lumsdaine2009focused}
\newlabel{eq:magnification2}{{1.10}{71}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.23}{\ignorespaces Raw images of a point source simulated with different magnifications. From top left to bottom right: \textit  {m = 1, m = 0.5, m= 0.25, m = 0.1}. }}{72}}
\newlabel{fig:rawpleno201}{{1.23}{72}}
\citation{lumsdaine2009focused}
\citation{lumsdaine2008full}
\citation{guillemin1990symplectic}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Plenoptic Camera 2.0: a Geometrical Optics Analysis}{73}}
\newlabel{sec:phase2.0}{{1.7}{73}}
\newlabel{eq:phase201}{{1.11}{73}}
\newlabel{eq:momentum2}{{1.12}{73}}
\newlabel{eq:1Dintensity}{{1.13}{73}}
\citation{georgiev2011plenoptic}
\newlabel{eq:transmatrix1}{{1.14}{74}}
\newlabel{eq:transmatrix2}{{1.15}{74}}
\newlabel{eq:transmatrix3}{{1.16}{74}}
\newlabel{eq:transmatrix4}{{1.17}{74}}
\newlabel{eq:transmatrix8}{{1.18}{74}}
\newlabel{eq:transmatrix5}{{1.19}{74}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.24}{\ignorespaces  System formed by a single lenslet. The rays at the main lens image plane are transformed into the rays at the sensor plane by the lenslet. The transformation can be described by a matrix \textit  {A}. }}{75}}
\newlabel{fig:basystem}{{1.24}{75}}
\newlabel{eq:transmatrix6}{{1.20}{75}}
\newlabel{eq:transmatrix7}{{1.21}{75}}
\newlabel{eq:radiance}{{1.22}{76}}
\newlabel{eq:radiance2}{{1.23}{76}}
\citation{georgiev2006light}
\@writefile{lof}{\contentsline {figure}{\numberline {1.25}{\ignorespaces  Sampling of the light field by plenoptic 2.0 camera. For each of the two points represented, red and green, The total range of directional coordinates are sampled by three different lenslets. For one position three directions are sampled, with a resolution of d/a. Therefore the directional sampling in plenoptic 2.0 is made across many lenslets. This can be seen in the phase space. Lenset B and C sample 2 directions indicated with the same number in the ray diagram and the phase space. Lens let A only samples one direction of the red point. }}{77}}
\newlabel{fig:phaseba}{{1.25}{77}}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Plenoptic 2.0 Rendering}{77}}
\newlabel{sec:rendering201}{{1.8}{77}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.26}{\ignorespaces  Image rendering with the focused plenoptic camera. One pixel of the rendered image is given by the integration on all the directions $d/b$ associated with a given position. The integration takes place across the lenslet and is represented by the vertical lines. Each lenslet is represented by the diagonal lines. }}{78}}
\newlabel{fig:render20}{{1.26}{78}}
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Conclusions}{78}}
\@setckpt{./TeX_files/chapter01}{
\setcounter{page}{80}
\setcounter{equation}{23}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{9}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{26}
\setcounter{table}{0}
\setcounter{float@type}{4}
\setcounter{parentequation}{0}
\setcounter{r@tfl@t}{0}
\setcounter{listing}{0}
}
